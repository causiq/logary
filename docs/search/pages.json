{"1":{"id":"1","title":"","subtitle":["Professional logging, metrics and analytics for your apps","JS Quickstart",".Net Core Quickstart","Targets / Sinks","How does it work?","JS Documentation",".Net Core Documentation","FAQs","Tutorials","License ","&"," Credits","Logary Prometheus for .Net Core","Logary Rutta","Pricing"],"description":"","body":"Logary v5 â€” Professional logging, metrics and analytics for your apps Logary Analytics Logary is awesome for analytics and logging. Built with   for developers and business analysts.  Star Logary    Follow @logary Would you like to  proactively handle any negative experiences  that your users '  are having? Maybe you ' re ðŸ¤’/ðŸ˜´ giving all your interaction data to large american corporations Â®? Or do you just want to measure  app latency  and  track revenue ? Then you ' ve come to the right place, because Logary solves that for you. Logary is a logging, tracing and metric library for .Net and JS as well as a stand-alone, â˜-native log router/ingress called Rutta. How does it work? .Net package   JS package Learn how to add analytics to your web/react-native apps. Instrument your backend services for a cloud native architecture. Logary can send logs, metrics and spans to a wide range of targets. Have a look here to see what ' s available! Let ' s have a look at this site and how we do analytics here... Read up on how to use the JavaScript library Read up on how to use the library Layout for FAQ page. Lorem ipsum dolor sit amet, consectetuer adipiscing elit Learn how to use Logary to visualise the state and interactions with your apps. Layout for license  &  credits page. Consectetuer adipiscing elit. xmlSpace= \" preserve \" > With  Logary.Prometheus  you can expose you app metrics for Prometheus and Grafana. A stand-alone, cloud-native log router and ingestion point for HTTP, UDP, ZeroMQ, TCP, and more. Purchase a commercial license to super-charge your company ' s logging, metrics and analytics, and improve Logary! Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/\",\"query\":{},\"buildId\":\"development\"}","href":"/"},"2":{"id":"2","title":".Net Quickstart","subtitle":["Download .Net Core 2.2",".Net Core 2.2","Create your first application","Install the package","Hello World (F#)","Hello World (C#)"],"description":"","body":"Logary â€” .Net Quickstart Logary Analytics Start .Net Quickstart   Expected reading time:  4  minutes Download the  .NET Core 2.2 SDK  to try .NET Core on your Windows, macOS, or Linux machine. Visit  dotnet/core  if you prefer to use Docker containers. All .NET Core versions are available at  .NET Core Downloads  if you ' re looking for another .NET Core version. The latest version is  .NET Core 2.2  New features include: framework-dependent deployments, startup hooks, AAD authentication with Azure SQL, and support for Windows ARM32. After installing the .NET Core SDK, open a command prompt. Type the following dotnet commands to create and run a C# application. dotnet new console dotnet run After installing the .NET Core SDK, open a command prompt. Type the following dotnet commands to create and run a C# application. Hello World! The first step is to install the Logary package(s) from NuGet. paket add logary --version  \" > = 5.0.0 \" Or you ' re using NuGet/VS... Install-Package Logary -Version 5.0.0-rc.10 module  Logary.ConsoleApp.Program\n\n open  System\n open  Hopac\n open  Logary\n open  Logary.Message\n open  Logary.Configuration\n open  Logary.Targets\n\n [ < EntryPoint > ] \n let  main argv =\n   use  mre =  new  System.Threading.ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n\n   let  logary =\n    Config.create  \" Logary.ConsoleApp \"   \" laptop \" \n    | >  Config.target (LiterateConsole.create LiterateConsole.empty  \" console \" )\n    | >  Config.ilogger (ILogger.Console Debug)\n    | >  Config.build\n    | >  run\n\n   let  logger = logary.getLogger  \" Logary.HelloWorld \" \n\n  logger.info (eventX  \" Hello world \" )\n\n  mre.Wait()\n   0 ï»¿ namespace   Logary.CSharpExample \n{\n     using  System;\n     using  System.Threading;\n     using  System.Threading.Tasks;\n     using  Configuration;\n     using  CSharp;\n     using  Targets;\n     using  Adapters.Facade;\n\n     public   static   class   Program \n    {\n         public   static  Task < LogManager >   StartLiterate ( ) \n        {\n             return  LogaryFactory.New( \" Logary.CSharpExample \" , \" laptop \" ,\n                with = >  with.InternalLogger(ILogger.NewConsole(LogLevel.Debug))\n                        .Target < LiterateConsole.Builder > ( \" console1 \" ));\n        }\n\n         public   static   async  Task  SampleUsage ( Logger logger ) \n        {\n             // without async \n            logger.LogSimple(MessageModule.Event(LogLevel.Info,  \" User logged in \" ));\n            \n             // await placing the Hello World event in the buffer \n             await  logger.LogEvent(LogLevel.Debug,  \" Hello world. Important? {important} \" ,  new \n            {\n                important =  \" yes \" \n            });\n\n             // await logging the fatal event and getting an ack back from each of the configured \n             // targets \n             await  logger.LogEvent(LogLevel.Fatal,  \" Fatal application error on finaliser thread. \" , waitForAck:  true );\n\n             await  logger.LogEvent(LogLevel.Verbose,  \" We need to log this with backpressure. \" ,  new \n            {\n                tags =  new [] {  \" tag1 \" ,  \" tag2 \"  }\n            });\n\n             // alternatively, you can use the ack-explicit functions together with the \n             // data object model that ' s MessageModule. \n             var  message = MessageModule.Event(LogLevel.Warn,  \" Here be dragons! \" );\n             await  logger.LogWithAck(message);\n\n             var  val = logger.Time(() = > \n                    {\n                         for  ( int  i =  0 ; i  <   100 ; i++)\n                            Thread.Sleep( 1 );\n\n                         return   32 ;\n                    },  \" sample.config.computeAnswerToEverything \" )\n                ();\n\n             await  logger.LogEventFormat(LogLevel.Warn,\n                 \" {horses} is the answer to the universe and everything \" ,\n                val);\n\n             await  logger.Time(\n                    () = >  logger.LogEvent(LogLevel.Debug,  \" I wonder how long this takes \" ))\n                ();\n\n             try \n            {\n                 throw   new  ApplicationException( \" thing went haywire \" );\n            }\n             catch  (Exception e)\n            {\n                 await  logger.LogEventFormat(LogLevel.Fatal,  \" Unhandled {exception}! \" , e);\n            }\n        }\n\n         public   static   void   SampleCibryyUsage ( Cibryy.Logging.ILogger logger ) \n        {\n           Cibryy.Core.Work(logger);\n           Cibryy.Core.WorkBackpressure(logger);\n           Cibryy.Core.ErrorWithBP(logger);\n           Cibryy.Core.SimpleWork(logger);\n           Cibryy.Core.GenerateAndLogExn(logger);\n           Cibryy.Core.StaticWork();\n        }\n\n         public   static   int   Main ( string [] args ) \n        {\n             // normal console app boilerplate; \n             var  mre =  new  ManualResetEventSlim( false );\n            System.Console.CancelKeyPress += (sender, arg) = >  mre.Set();\n\n             var  logary = StartLiterate().Result;\n            \n             // Usage with a library: \n            LogaryFacadeAdapter.Initialise < Cibryy.Logging.ILogger > (logary);\n             var  logger = logary.GetLogger( \" main \" );\n            SampleCibryyUsage(LoggerCSharpAdapter.Create < Cibryy.Logging.ILogger > (logger));\n            \n             // Usage in this program: \n            SampleUsage(logger).Wait();\n                \n             // Wait for CTRL+C \n            mre.Wait();\n             return   0 ;\n        }\n    }\n}\n Download .Net core 2.2 .Net Core 2.2 Create your first application Install the package Hello F# Hello C# Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/quickstart\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-dotnet-quickstart"},"3":{"id":"3","title":"JavaScript Quickstart","subtitle":["Install the package"],"description":"","body":"Logary â€” Javacript Quickstart Logary Analytics Start JavaScript Quickstart   Expected reading time:  2  minutes The first step is to install the Logary package from npm. npm install --save logary Or you ' re using yarn... yarn add logary Install the package Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/js/quickstart\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-js-quickstart"},"4":{"id":"4","title":"Target / Sinks","subtitle":["InfluxDb Target","File target (alpha level)","Configuration","Policies ","&"," specifications","Performance","Handling of errors","Invariants","Overview of buffers","Notes on FILE_FLAG_NO_BUFFERING","Work to be done","Stackdriver target","Configuration","Further work","Jaeger Tracing target","Install jaeger tracing","Usage","What does it look like?","AliYun Log Service target","Usage","What does it look like?","Microsoft Azure Application Insights target","Commercial Targets","Mixpanel","OpsGenie","elmah.io","SumoLogic (community-contributed)","Want your SaaS-logging service as a Target?"],"description":"","body":"Target / Sinks Logary Analytics Start Target / Sinks   Expected reading time:  2  minutes Suppose you ' re measuring values coming from a car. This is what that could look like: Events will be logged to InfluxDb like such:   \" pointName, event=template, ctx1=ctxval1, ctx2=ctxval2 field1=fieldval1, field2=fieldval2 value=1i 14566666xxxx \" In other words, fields will be influx values and context fields will be influx tags. The timestamp of the Message will be at the end as the timestamp of the sent line Events will be logged in these influx measure names, so that you could e.g. put    \" event_fatal \"   as an annotation in Grafana:  event_verbose   event_debug   event_info  event_warn   event_error   event_fatal  Logary ' s file target is primarily geared towards systems that are running on single machines as it prints a human-readable format, rather than a machine- readable one. The default configuration of the file target rotates log files greater than 200 MiB and deletes log files when the configured folder size is larger than 3 GiB. Folders that don ' t exist when the target starts are automatically created on target start-up in the current service ' s security context. Should the calls to create the folder fail, the target is never started, but will restart continuously like any ther Logary target. let  fileConf =\n  { File.FileConf.create logDir (Naming ( \" {service}-{host}-{datetime} \" ,  \" log \" )) }\n\n // ... withTargets [ \n  File.create fileConf  \" file \" \n // ] ... Or in C#: // set  ' logDir '  to specific path like Environment.CurrentDirectory if you are on windows \n.Target < File.Builder > (\n     \" file \" ,\n    file = >  file.Target.FileSystem( new  FileSystem.DotNetFileSystem(logDir))\n                       .Naming( \" {service}-{host}-{datetime} \" ,  \" log \" ).Done()) You can specify a number of deletion and rotation policies when configuring the file target. The deletion policies dictate when the oldest logs should be deleted, whilst the rotation policies dictates when the files should be rotated (thereby the previous file archived). Furthermore, you can specify a naming specification that dictates how the files should be named on disk. Deletion of files happen directly when at least one deletion policy has triggered. Rotation of files happen directly when at least one rotation policy has triggered. Naming specifications should automatically be amended with sequence number, should that be required. The   File   target is a performance-optimised target. Logging always happens on a separate thread from the caller, so we try to reach a balance between throughput and latency on ACKs. On Windows, overlapped IO is not used, because the files are opened in Append mode, should have equivalent performance. This means we should have similar performance on Linux and Windows. The formatters used for the  File  target should be writing to  TextWriter  instances to avoid creating extra string copies in memory. The file target is thought as a last-chance target, because by default, logs should be shipped from your nodes/machines to a central logging service. It can also be nicely put to use for local console apps that need to log to disk. Non-target-fatal  IOExceptions , for example when NTFS ACKs file deletes but still keeps the file listable and available for some duration afterwards are retried on a case-by-case basis. Internal Warn-level messages are logged. Fatal  IOExceptions  â€“ more other cases; directory not found, file not found, etc. are not retried. The target should crash and restart. Its current batch is then retried forever, while logging internal Fatal-level exceptions. The File target is modelled as a transaction log and trades speed against safety that the contents have been written to disk, but does not do the bookkeeping required to use FILE_FLAG_NO_BUFFER. Fatal level events are automatically flushed/fsync-ed. Only a single writer to a file is allowed at any given time. This invariant exists because atomic flushes to files are only possible on Linux up to the page size used in the page cache. Only asynchronous IO is done, i.e. the Logary worker thread is not blocked by calls into the operating system. Because of the overhead of translating callbacks into Job/Alt structures, we try to write as much data as possible on every call into the operating system. This means that Messages to be logged can be ACKed in batches rather than individually. If your disk collapses while writing log messages (which happens once in a while and happens frequently when you have thousands of servers), the target should save its last will and then retry a configurable number of times after waiting an exponentially growing duration between each try. It does this by crashing and letting the supervisor handle the failure. After exhausting the tries, the batch of log messages is discarded. If there are IO errors on writing the log messages to disk, there ' s no guarantee that there won ' t be duplicate log lines written; however, they ' re normally timestamped, so downstream log ingestion systems can do de-duplication. This is from the batched nature of the File target. You write a Message from your call-site, this message is synchronised upon between the sending thread and the receiving thread using Hopac. If you use one of the logWithAck functions, placing the message in the RingBuffer can be awaited (or NACKed)  If you use the logSimple function, the synchronisation is hoisted onto the concurrency scheduler ' s pending queue and raced with a timeout to be discarded if the logging subsystem is overwhelmed. Once the Message is in the RingBuffer of the File target, it ' s either removed by itself, or as part of a batch, to be serialised to string. The serialisation function reads through the values of the message and uses the formatter function to write those values into a TextWriter. The TextWriter is normally a StreamWriter writing to a FileStream. This means no extra strings need be created through concatenation. Depending on the inProcBuffer configuration flag, the TextWriter either supports buffering, which buffers the string inside the CLR process, or writes directly to the underlying file handle, which transitions the data to the kernel ' s ioctl subsystem. By default we don ' t buffer here. Depending on the flushToDisk configuration flag, the FileStream is or is not called with Flush(true), which forces a disk synchronisation. By default we let the page cache buffer these writes, to trade safety against throughput. This is similar to how most other targets work. Depending on the writeThrough flag; Messages written with the File target is only ACKed when they are durably on disk. Defaults to true. Note that disposing Logary, e.g. during application exit flushes all buffers. I ' ve been considering supporting   NO_BUFFERING  but this would require callers to possibly wait for the 4096 bytes buffer to fill up before ACKing messages. However, for low-throughput logging, where each log line may be around, say, 240 bytes of text, having the NO_BUFFERING flag set may end up losing us more than it gains us. https://support.microsoft.com/en-us/kb/99794 https://stackoverflow.com/questions/317801/win32-write-to-file-without-buffering https://winntfs.com/2012/11/29/windows-write-caching-part-2-an-overview-for-application-developers/ https://msdn.microsoft.com/en-us/library/windows/desktop/cc644950(v=vs.85).aspx https://msdn.microsoft.com/en-us/library/windows/desktop/aa363772(v=vs.85).aspx https://stackoverflow.com/questions/8692635/how-do-disable-disk-cache-in-c-sharp-invoke-win32-createfile-api-with-file-flag https://stackoverflow.com/questions/122362/how-to-empty-flush-windows-read-disk-cache-in-c https://ayende.com/blog/174785/fast-transaction-log-windows These runs illustrate the above points in a more direct manner. In all of these cases we ' re writing 10K events to disk. inProcBuffer = false, flushToDisk = true, caller awaits all acks at the end This is the safest option and takes 1.3 seconds to log, format and write 10K messages. I 2016-11-08T11:04:00.6125063+00:00: Event 1 [Logary.Samples.main] number = >  1 ... [12:04:02 DBG] Flushing to disk. ... I 2016-11-08T11:04:02.0201345+00:00: Event 9402 [Logary.Samples.main] number = >  9402 [12:04:02 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9403 [Logary.Samples.main] number = >  9403 I 2016-11-08T11:04:02.0201345+00:00: Event 9404 [Logary.Samples.main] number = >  9404 ... I 2016-11-08T11:04:02.0891350+00:00: Event 10000 [Logary.Samples.main] number = >  10000 [12:04:02 DBG] Flushing to disk. ... The interleaved flushes shows the batching functionality of the File target in action. inProcBuffer = false, flushToDisk = true, caller awaits all ack after each This example represents the worst-case usage of the safest configuration. I 2016-11-08T11:14:42.9071732+00:00: Event 1 [Logary.Samples.main] number = >  1 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:14:42.9711735+00:00: Event 2 [Logary.Samples.main] number = >  2 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9403 [Logary.Samples.main] number = >  3 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9404 [Logary.Samples.main] number = >  4 [12:14:42 DBG] Flushing to disk. ... I 2016-11-08T11:15:04.7635448+00:00: Event 10000 [Logary.Samples.main] number = >  10000 [12:15:04 DBG] Flushing to disk. With this configuration, the File target would still batch other threads '  Messages but since this example has a single thread producer, there ' s only a single Message available for the target every loop. inProcBuffer = true, flushToDisk = false, writeThrough=false caller awaits all acks at the end This is the least safe and most speedy option. Useful when you ' re shipping logs away from the node and configure those shippers in a safer manner. In this case, .Net and the operating system and the device drivers decide when to flush. On exit/dispose of Logary, all targets are always flushed. [12:32:05 INF] Event 1 ... [12:32:06 INF] Event 10000 [12:32:48 DBG] Shutting down Logary. ... [12:32:48 DBG] Flushing to disk. In this example, the actual time taken is dominated by the time to generate the messages. Unit test rotation code Then enable rotation Harden against exceptions during writes â€“ mock FileSystem Development has been sponsored by   Tradera.com.  Logary also includes a logging target for   Google Cloud Stackdriver.  The target can be configured like so: open  Logary.Targets.Stackdriver\n\n let  projectId =  \" your gcloud project id \" \n // either a custom name, or you can use one of the well-known stream names that you can retrieve from [the lists](https://cloud.google.com/logging/docs/view/logs_index) \n // this name doesn ' t have to be url-encoded as per the spec, the target will do that for you \n // the specified log should exist before use \n let  logname =  \" the stream you want to log to \" \n // create your monitored resource: \n let  resource = ComputeInstance( \" my zone \" ,  \" my instanceId \" )\n // or container: \n // let resource = Container( \" my cluster \" ,  \" my namespace \" ,  \" my instanceID \" ,  \" my pod \" ,  \" my name \" ,  \" my zone \" ) \n // or appengine: \n // let resource = AppEngine( \" my moduleId \" ,  \" my version \" ) \n\n let  conf = StackdriverConf.create(projectId, logname, resource) Then, within withTargets: Stackdriver.create conf  \" target-name \" batching flushing the underlying library doesn ' t provide a flush mechanism yet  https://www.jaegertracing.io/  https://www.jaegertracing.io/download/ add ambientSpanId middleware to the target, if you want to use ambient span jaegerTargetConf | >  TargetConf.middleware Middleware.ambientSpanId then create span for some tracing, log message as usual: use  rootSpan = logger.buildSpan () | >  Span.setMessage (eventX  \" root span \" ) | >  Span.start\n\n do!  eventX  \" before some action: {userId} \"   > >  setField  \" userId \"   123  | >  logger.infoWithBP\n\n // do some action : ... \n\n do!  eventX  \" after some action: {orderId} \"   > >  setField  \" orderId \"   321  | >  logger.infoWithBP\n\n let  conStr =  \" Host=;Database=;Username=;Password=; \" \n\n use  childSpan = Span.create logger | >  Span.setMessage (eventX  \" child span \"   > >  tag  \" DB Query \"   > >  tag  \" Postgresql \"   > >  setContext  \" conn str \"  conStr) | >  Span.start\n\n let  sql =  \" select count(*) from xxx \" \n do!  eventX  \" query : {sql} \"   > >  setField  \" sql \"  sql  > >  setTimestamp (Instant.FromUnixTimeSeconds  1 L) | >  logger.infoWithBP if not using ambient span, you can use Message.setSpanId for log message and Span.setParentSpanInfo for childSpan creation. do!  eventX  \" after some action: {orderId} \"   > >  setField  \" orderId \"   321   > >  setSpanId rootSpan.info.spanId | >  logger.infoWithBP\n\n // use explicitly setParentSpanInfo style, since we use hopac `do! timeOutMillis 100` before (the ambientSpanId middleware will not be guaranteed) \n let  childSpan = Span.create logger | >  Span.setMessage (eventX  \" child span \"   > >  tag  \" DB Query \"   > >  tag  \" Postgresql \"   > >  setContext  \" conn str \"  conStr) | >  Span.setParentSpanInfo rootSpan.info | >  Span.start LogaryFactory.New( \" demoService \" ,\n                    conf = >  conf\n                            .InternalLoggingLevel(LogLevel.Verbose)\n                            .Target < Debugger.Builder > ( \" internal.debugger \" , tb = >  tb.UseForInternalLog())\n                            .Target < Logary.Targets.Console.Builder > ( \" internal.console \" , tb = >  tb.UseForInternalLog())\n                            .Target < LiterateConsole.Builder > ( \" console1 \" )\n                            .Target < AliYun.Builder > ( \" AliYunLog \" , tb = >  {\n                                 tb.MinLevel(LogLevel.Verbose)\n                                 .Target\n                                 .ConfClient( \" key \" ,\n                                              \" keyid \" ,\n                                              \" endpoint \" )\n                                 .ConfLogLocation( \" project \" ,  \" logstore \" )\n                                 .SetConnectTimeOut( 1000 )\n                                 .SetReadWriteTimeOut( 5000 )\n                                 .Done();\n                            })\n                    ); Target for   Microsoft Azure AppInsights   logs the events as TRACE-messages (or Events/Metrics with a different MappingConfiguration). You need to set the API-key first. Then when you go to Azure Portal Application Insights and  Overview - >  Search   you should be able to find the targets from there. Metrics goes to   Metrics Explorer - >  Add Chart - >  Custom.    More info... Logary is a production-grade logging and metrics library. We ' ve also built targets that integrate with external paid services. These are listed here. Learn how people use your app with the world ' s most advanced mobile  &  web analytics. [Purchase today](mailto:henrik@haf.se?subject=Logary Mixpanel Target) Ship logs from your iOS, Android app Ship logs and handle user identification and unique-id tracking from web Use your own domain and server (over HTTPS) Logary listens on your server and forwards your events into Mixpanel Add granular server-side event filtering/enriching/correlation for better insights before shipping them onwards. Log web app usage even when Mixpanel is blocked client-side We like open source â€“ so in the purchase the reference source is provided so that it can be debugged like the rest of Logary. Send an e-mail to purchase This assumes you have an account at  Mixpanel.   You can ' t rely on any one notification method for critical alerts. Get alert notifications via iOS  &  Android push, SMS, and phone calls; escalate automatically to team members if the alert is not acknowledged. The Logary target for OpsGenie ensures that you can bring in your Logging and Metrics into your daily operations. Connect using your own API key Make Logary events into new alerts Supports custom  ' enrichers '  to let you specify e.g. user, teams, recipients, tags, entity and notes, to name a few. Ready to use from both F# and C# Use derived metrics to create load-level alerts Stay on top of your infrastructure Avoid blacklisting your transactional e-mail service This assumes you have an account at   OpsGenie.      source https://www.nuget.org/api/v2   nuget Logary.Targets.Elmah.Io  OR:  Install-Package Logary.Targets.Elmah.Io  Configure elmah.io just like you would any normal target. # if  INTERACTIVE\n#I  \" bin/Release \" \n#r  \" Hopac.Core.dll \" \n#r  \" Hopac.dll \" \n#r  \" NodaTime.dll \" \n#r  \" Logary.dll \" \n#r  \" Logary.Riemann.dll \" \n#endif\n\n open  System\n open  NodaTime\n open  Hopac\n open  Logary\n open  Logary.Configuration\n open  Logary.EventProcessing\n open  Logary.Targets\n open  Logary.Targets.ElmahIO\n open  System.Threading\n\n [ < EntryPoint > ] \n let  main argv =\n   use  mre =  new  ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n\n   let  logary =\n     let  elmahioConf =\n      { logId = Guid.Parse(Environment.GetEnvironmentVariable( \" ELMAH_IO_LOG_ID \" ))\n        apiKey =  \" api key form elmah io \" }\n\n    Config.create  \" Logary.ElmahIO \"   \" localhost \" \n    | >  Config.targets [\n        Console.create Console.empty  \" console \" \n        ElmahIO.create elmahioConf  \" elmah.io \" \n      ]\n    | >  Config.processing (Events.events | >  Events.sink [ \" console \" ; \" elmah.io \" ;])\n    | >  Config.build\n    | >  run\n\n   let  logger =\n    logary.getLogger (PointName [|  \" Logary \" ;  \" Samples \" ;  \" main \"  |])\n\n  Message.eventFormat( \" {userName} logged in \" , [|  \" haf \"  |])\n  | >  Logger.logSimple logger\n\n  Message.eventFormat (Info,  \" {userName} logged in \" , [|  \" adam \"  |])\n  | >  Logger.logSimple logger\n\n  mre.Wait()\n   0 Or from C#: // ... \n.Target < ElmahIO.Builder > (\n   \" elmah.io \" ,\n  conf = >  conf.Target.WithLogId( \" GUID_HERE \" )) You ' ll get the same view by logging this Message: type   Tenant   =\n  { tenantId : string\n    permissions : string }\n\n let  exnMsg =\n  Message.event Error  \" Unhandled exception \" \n  | >  Message.setSimpleName  \" A.B.C \" \n  | >  Message.setFieldFromObject  \" tenant \"  { tenantId =  \" 12345 \" ; permissions =  \" RWX \"  }\n  | >  Message.setContextFromMap (Map\n    [  \" user \" , box (Map\n        [  \" name \" , box  \" haf \" \n           \" id \" , box  \" deadbeef234567 \" \n        ])\n    ])\n  | >  withException Message.addExn This assumes you have an account at   elmah.io. SumoLogic is a hosted service (at about 99 USD per month) that unifies logging, metrics, analytics and dashboards in a single service. As such it ' s a perfect Target for Logary, since Logary supports both logs and metrics. Have a look at @neoeinstein ' s   Logary.Targets.SumoLogic   for the official docs and a sample of how to use it.  source https://www.nuget.org/api/v2   nuget Logary.Targets.SumoLogic  Absolutely! You have two options; Send a PR with your target that is of equivalent quality as the rest of the code-base, including documentation, code-doc, the C# builder API and a sample in this file. Then keep that code up-to-date when Logary evolves and your SaaS service changes its APIs. Send me an e-mail and I ' ll target the target for you. Pricing: a small initial fee and then a monthly maintenance fee, you ' ll have a beautiful way of getting logs and metrics to your servers!. This is by far the easiest option and ensures that your Target is stable and easy to use for your customers. I ' ll even write some Markdown/HTML-formatted docs for your site about how to use Logary with your target. InfluxDb Target File target (alpha level) Stackdriver target Jaeger Tracing target AliYun Log Service target Microsoft Azure Application Insights target Commercial Targets Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/targets\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-dotnet-targets"},"5":{"id":"5","title":"","subtitle":[],"description":"","body":"Logary Analytics Start How Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/tutorials/how\",\"query\":{},\"buildId\":\"development\"}","href":"/tutorials/how-does-logary-work?"},"6":{"id":"6","title":"","subtitle":[],"description":"","body":"Logary Analytics Start Logary JS docs Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/js/docs\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-js-documentation"},"7":{"id":"7","title":".Net Core Documentation","subtitle":["PointName","Context","Fields","Gauges","Tags","SinkTargetNames","SinkTargetNames","Rule ","&"," Hierarchical logging ","&"," Filter ","&"," Minimum level","Log Level","Logging from modules","Logging from a class","Logging fields ","&"," templatings","Metrics ","&"," EventProcessing pipeline","Building"],"description":"","body":".Net Core Documentation Logary Analytics Start .Net Core Documentation   Expected reading time:  2  minutes Suppose you ' re measuring values coming from a car. This is what that could look like: module  Bicycle.SupervisorProcess\n open  Logary\n open  Logary.Message\n\n //  \" the sensor \" \n let  logger = Log.create  \" Car.SupervisorProcess \" \n\n let  tyreTick () =\n   //  \" the event is triggered, e.g. via a polling supervisor \" \n  logger.info (\n    eventX  \" Tyres \" \n     > >  addGauge  \" front \"  (Gauge (Float  79.2421 , Units.Pascal)))\n     > >  addGauge  \" back \"  (Gauge (Float  90.159 , Units.Pascal))) context are generally classified into these categories: (you can try these code on test.fsx in Logary.Tests) prefix with  \" _fields. \" Fields are the structured data when you use structure logging like (https://messagetemplates.org/), there are mainly two style to achieve this. type   SomeInfo () =\n   member  x.PropA =\n     45 \n   member  x.PropB =\n    raise (Exception ( \" Oh noes, no referential transparency here \" ))\n with \n   interface  IFormattable  with \n     member  x.ToString (format, provider) =  \" PropA is 45 and PropB raise exn \" \n\n let  oneObj = SomeInfo ()\n\nMessage.eventFormat (Info,  \" Hey {userName}, here is a default {info} and stringify {$info} and destructure {@info} \" ,  \" You \" , oneObj)\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePath.format\n\n val  it : string =\n   \" I 2018-01-26T09:08:21.6590074+00:00: Hey  \" You \" , here is a default  \" PropA is  45   and  PropB raise exn \"  and stringify  \" FSI_0002+SomeInfo \"  and destructure SomeInfo { PropB:  \" The property (PropB) accessor threw an (TargetInvocationException): Oh noes, no referential transparency here \" , PropA: 45 } [somewhere.this.message.happened]\n  fields:\n    info = > \n      SomeInfo {\n        PropB = >   \" The property (PropB) accessor threw an (TargetInvocationException): Oh noes, no referential transparency here \" \n        PropA = >  45}\n    userName = >   \" You \" \" \n\n // or use this style: \n\nMessage.event Info  \" user write some info \" \n| >  Message.setField  \" userName \"   \" You \" \n| >  Message.setField  \" data \"  oneObj\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePath.format Result in: val  it : string =\n   \" I 2018-01-26T09:14:08.3286743+00:00: user write some info [somewhere.this.message.happened]\n  fields:\n    data = > \n      SomeInfo {\n        PropB = >   \" The property (PropB) accessor threw an (TargetInvocationException): Oh noes, no referential transparency here \" \n        PropA = >  45}\n    userName = >   \" You \" \" prefix with  \" _logary.gauge. \" which value is Gauge(float, units). An instantaneous value. Imagine the needle showing the speed your car is going or a digital display showing the same instantaneous metric value of your car ' s speed. you can add gauges with one message, or use gauge as the message. The difference between them is, if you use gauges as the message, the value in message are auto generate by gauges when formatting them : type   User   =\n  {\n    id      : int\n    name    : string\n    created : DateTime\n  }\n\n let  date20171111 =  DateTime.Parse( \" 2017-11-11 \" )\n let  foo () = { id =  999 ; name =  \" whatever \" ; created = date20171111}\n\n\n let  ex = exn  \" exception with data in it \" \nex.Data.Add ( \" data 1 in exn \" ,  1 )\nex.Data.Add ( \" data foo in exn \" , foo ())\nex.Data.Add (foo(), foo())\n\nMessage.event Error  \" ouch \" \n| >  Message.addExn ex\n| >  Message.addExn (exn  \" another exception \" )\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePathNewLine.format\n\n val  it : string =\n   \" E 2018-01-26T09:30:37.7648557+00:00: ouch [somewhere.this.message.happened]\n  others:\n    _logary.errors = > \n      -\n        System.Exception {\n          Message = >   \" another  exception \" \n          HResult = >  -2146233088}\n      -\n        System.Exception {\n          Message = >   \" exception   with  data  in  it \" \n          Data = > \n             \" data  1   in  exn \"  = >  1\n             \" data foo  in  exn \"  = > \n              User {\n                name = >   \" whatever \" \n                id = >  999\n                created = >  11/11/2017 12:00:00 AM}\n            - key = > \n                User {\n                  name = >   \" whatever \" \n                  id = >  999\n                  created = >  11/11/2017 12:00:00 AM}\n              value = > \n                User {\n                  name = >   \" whatever \" \n                  id = >  999\n                  created = >  11/11/2017 12:00:00 AM}\n          HResult = >  -2146233088}\n \" prefix with  \" _logary.tags \" which value is a set , tags are help with identity one type message when you do some pipeline processing. > \n-  let  pipeLine =\n-    Events.events\n-    | >  Events.tag  \" queue \" \n-    | >  Pipe.map ( fun  msg - >  {msg  with  value =  \" https://github.com/alexandrnikitin/MPMCQueue.NET \" })\n-\n-\n-\n-  let  logm =\n-   Config.create  \" svc \"   \" localhost \" \n-   | >  Config.target (Targets.Console.create Targets.Console.empty  \" my console target \" )\n-   | >  Config.processing pipeLine\n-   | >  Config.build\n-   | >  run\n-\n-  let  lg = logm.getLogger (PointName.parse  \" give.some.example.here \" )\n-\n- Message.event Info  \" MPMCQueue \" \n- | >  Message.tag  \" queue \" \n- | >  Message.tag  \" high-performance \" \n- | >  Message.tag  \" lock-free \" \n- | >  Message.tag  \" multiple-consumers \" \n- | >  lg.logSimple\n-\n- ;;\nI  2018 -01 -26 T09: 51 : 06.0523375 + 00 : 00 : https: //github.com/alexandrnikitin/MPMCQueue.NET [give.some.example.here] \n  others:\n    _logary.host = >   \" localhost \" \n    _logary.service = >   \" svc \" \n    _logary.tags = >  [ \" high-performance \" ,  \" lock-free \" ,  \" multiple-consumers \" ,  \" queue \" ] prefix with  \" _logary.sink.targets \" They are generally are set by Events Processing, you can define which targets (sinks) your message will go. if not set, message will go to all targets and let the targets themself to decide whether or not to accept it. let  pipeLine =\n   Events.events\n   | >  Events.tag  \" queue \" \n   | >  Pipe.map ( fun  msg - >  {msg  with  value =  \" https://github.com/alexandrnikitin/MPMCQueue.NET \" })\n   | >  Events.sink [ \" nice console \" ]\n\n let  logm =\n  Config.create  \" svc \"   \" localhost \" \n  | >  Config.target (Targets.Console.create Targets.Console.empty  \" my console target \" )\n  | >  Config.target (Targets.LiterateConsole.create Targets.LiterateConsole.empty  \" nice console \" )\n  | >  Config.processing pipeLine\n  | >  Config.build\n  | >  run\n\n let  lg = logm.getLogger (PointName.parse  \" give.some.example.here \" )\n\nMessage.event Info  \" MPMCQueue \" \n| >  Message.tag  \" queue \" \n| >  Message.tag  \" high-performance \" \n| >  Message.tag  \" lock-free \" \n| >  Message.tag  \" multiple-consumers \" \n| >  lg.logSimple this will only show on LiterateConsole, not normal Console. things you don ' t want to show on the message value, but show on the backstore. e.g: some structured data not belong the message template or data you can use in the EventProcessing Pipeline. Message.eventFormat (Info,  \" {userId} create an shopping list at {createdTime} \" ,  \" 9999 \" , DateTime.Now )\n| >  Message.setContext  \" user name \"   \" :) \" \n| >  Message.setContext  \" shopping list \"  [ \" cat \" ; \" cat food \" ; \" books \" ; \" drinks \" ]\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePath.format\n\n val  it : string =\n   \" I 2018-01-26T10:11:54.5221326+00:00:  \" 9999 \"  create an shopping list at 1/26/2018 6:11:54 PM [somewhere.this.message.happened]\n  fields:\n    userId = >   \" 9999 \" \n    createdTime = >  1/26/2018 6:11:54 PM\n  others:\n    user name = >   \" :) \" \n    shopping list = >  [ \" cat \" ,  \" cat food \" ,  \" books \" ,  \" drinks \" ] \" A logger have a minimum level which message ' s level below it is not processed when logging these message. Can give us Low overhead logging â€“ evaluate your Message only if a level is switched on. Especially when you use logging api with message factory. A logger ' s minimum level are config through Config.loggerMinLevel  \" a.b.* \"  LogLevel.Fatal on logary conf (usually globally) use a specific name or some hierarchy path. And can be switch on fly logm.switchLoggerLevel ( \" a.b.* \" , LogLevel.Info),this will only affect the loggers (its name, not its instance) which have been created beafore. e.g. the default level is Error on prod, use a pipe line detect an error message, switch to Info for 5 mins then change it back. can be use for auto collecting more useful info when things goes wrong. let  someRuleOnTarget =\n  Rule.empty\n  | >  Rule.setMinLevel LogLevel.Error  // this target will only get message about error level (inclusive) \n  | >  Rule.setPath (System.Text.RegularExpressions.Regex( \" a.b.c.* \" ))  // only accept message name under a.b.cxxxxx \n  | >  Rule.setAcceptIf ( fun  msg - >  msg | >  Message.hasTag  \" emergency \" )\n\n let  tconf =\n  Targets.LiterateConsole.create Targets.LiterateConsole.empty  \" nice console \" \n  | >  TargetConf.addRule someRuleOnTarget\n let  logm =\n  Config.create  \" svc \"   \" localhost \" \n  | >  Config.target tconf\n  | >  Config.loggerMinLevel  \" a.b.* \"  LogLevel.Fatal   // logger under a.bxxxx path only process Fatal message \n  | >  Config.loggerMinLevel  \" a.b.c.* \"  LogLevel.Info  // logger under a.b.cxxxx path can process message above Info \n  | >  Config.build\n  | >  run\n\n let  abc = logm.getLogger (PointName.parse  \" a.b.cxxx \" )\n let  ab = logm.getLogger (PointName.parse  \" a.bxxx \" )\n\nabc.verbose (Message.eventX  \" abc.Info \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // no invoke \nabc.error (Message.eventX  \" abc.Error \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // invoke, but will not go to target \nabc.error (Message.eventX  \" abc.Error with emergency tag \"   > >  ( fun  msg - >  printfn  \" invoke%s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n\nab.error (Message.eventX  \" ab.Error \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // no invoke \nab.fatal (Message.eventX  \" ab.Fatal \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n\n >  abc.verbose (Message.eventX  \" abc.Info \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // no invoke \n- ;;\n val  it : unit = ()\n\n >  abc.error (Message.eventX  \" abc.Error \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // invoke, but will not go to target \n- ;;\ninvoke abc.Error\n val  it : unit = ()\n\n >  abc.error (Message.eventX  \" abc.Error with emergency tag \"   > >  ( fun  msg - >  printfn  \" invoke%s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n- ;;\ninvokeabc.Error  with  emergency tag\n val  it : unit = ()\n\n >  [ 19 : 06 : 33  ERR] abc.Error  with  emergency tag  < a.b.cxxx > \n  others:\n    _logary.host = >   \" localhost \" \n    _logary.service = >   \" svc \" \n    _logary.tags = >  [ \" emergency \" ]\n\n >  ab.error (Message.eventX  \" ab.Error \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // no invoke \n- ;;\n val  it : unit = ()\n\n >  ab.fatal (Message.eventX  \" ab.Fatal \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n- ;;\ninvoke ab.Fatal\n[val19: 07 : 45   FTLit]  ab.Fatal:  unit < a.bxxx > \n  others:\n    _logary.host = >   \" localhost \" \n    =_logary.service = >   \" svc \" \n    _logary.tags  = >  [ \" emergency \" ] The highest log level is Fatal, which should be reserved for things that make your service/process crash. Things like;  \" my disk is full and I ' m a database trying to start \" , or  \" I ' m a 2-tier service built with a database, that I cannot do any work without \"  warrant the Fatal level. The next level is Error, which should be reserved for what you consider to be edge-cases. E.g. if the data received from a socket is corrupt, or there was an unhandled exception that you as a programmer did not have in your mental model while writing the code. These events should be logged at the Error level. At this level human beings are normally directly alerted. Warn is for things like 100 failed password attempts within 5 minutes, for one of your users, or a temporary network glitch while communicating with a  \" resource \"  such as your database. If these events for an anomaly persist over time, humans may be alerted. At Info level, I like to put events and gauges that measure company-relevant stuff, like when users sign in, sign up, an integration has to perform a retry or a service was started/restarted. Debug level is the default level and the work-horse. You normally log all metrics at this level. Verbose is the level when you want that little extra. Not normally enabled. Let ' s say you have a module in your F# code that you want to log from. You can either get a logger like shown in Hello World, or you can do something like this: module  MyCompany.Sub.MyModule\n\n open  Logary\n\n let  logger = Logging.getCurrentLogger ()\n\n let  logInUser () =\n   // do something \n  Message.event Info  \" User logged in \"  | >  Logger.logSimple logger\n   // do more stuff If you want to name your logger with a specific name, you can use Logging.getLoggerByName instead. (This is different for the Facade file) Similarly, sometimes you want to log from a class, and perhaps log some metrics too. namespace  MyCompany.Sub\n\n open  Logary\n\n type   Worker () =\n   let  logger =\n    Logging.getLoggerByName  \" MyCompany.Sub.Worker \" \n\n   let  workName =\n    PointName [|  \" MyCompany \" ;  \" Sub \" ;  \" Worker \" ;  \" workDone \"  |]\n\n   let  getAnswers (amount : float) =\n     // work work work \n     42  * amount\n\n   member  x.Work (amount : float) =\n     // Initially, log how much work is to be done \n     // the only  \" supported \"  metric is a gauge (a value at an instant) \n    Message.gauge workName amount | >  Logger.logSimple logger\n\n     // do some work, logging how long it takes: \n     let  everything = Logger.time logger ( fun  () - >  getAnswers amount)\n\n     // return result \n    everything In this example you learnt how to send arbitrary metrics to Logary (the gauge) and also how to time how long certain method calls take in your system. Make it a habit to log these sort of gauges all over your code base while you write your code, to make it much easier to understand the system as it develops. In fact, the more you do this, the more use you will have of Logary and of the dashboard you put up in Kibana (via Logstash) or Grafana (via InfluxDb). Put it up on a big TV in your office and you ' ll develop a second sense of whether the system is doing well or not, just from looking at the graphs. The templates syntax can be found here:  Message Templates are a superset of standard .NET format strings, so any format string acceptable to string.Format() will also be correctly processed by logary. Property names are written between and braces Formats that use numeric property names, like 0 and 1 exclusively, will be matched with the Format method ' s parameters by treating the property names as indexes; this is identical to string.Format() ' s behaviour  If any of the property names are non-numeric, then all property names will be matched from left-to-right with the Format method ' s parameters Property names may be prefixed with an optional operator, @ or $, to control how the property is serialised Property names may be suffixed with an optional format, e.g. :000, to control how the property is rendered; these format strings behave exactly as their counterparts within the string.Format() syntax Sometimes you need a metric that runs continuously over time. A Ticker can be seems as a metric, it can be auto triggered or by manually. A ticker can be chained in an pipe line (EventProcessing). We have some windows performance counter metrics that you can use. But you sometimes want to chain metrics from events or gauges happening inside your own application. We have some windows performance counter metrics that you can use. module  Program\n\n open  System\n open  System.Threading\n open  Hopac\n open  Logary\n open  Logary.Configuration\n open  NodaTime\n open  Logary.Targets\n open  Logary.Metrics.WinPerfCounters\n open  Logary.EventProcessing\n\n module  Sample =\n\n   let  randomWalk pn =\n     let  reducer state =  function \n      | _ - > \n        state\n\n     let  ticker (rnd : Random, prevValue) =\n       let  value =\n         let  v = (rnd.NextDouble() -  0.5 ) *  0.3 \n         if  abs v  <   0.03   then  rnd.NextDouble() -  0.5 \n         elif  v + prevValue  <   -1.  || v + prevValue  >   1.   then  -v + prevValue\n         else  v + prevValue\n\n       let  msg = Message.gauge pn value\n\n      (rnd, value), msg\n\n     let  state =\n       let  rnd = Random()\n      rnd, rnd.NextDouble()\n\n    Ticker.create state reducer ticker\n\n [ < EntryPoint > ] \n let  main argv =\n   let   inline  ms v = Duration.FromMilliseconds (int64 v)\n   let  pn name = PointName [|  \" Logary \" ;  \" Samples \" ; name |]\n   use  mre =  new  ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n   let  clock = SystemClock.Instance\n   let  tenSecondsEWMATicker = EWMATicker (Duration.FromSeconds  1 L, Duration.FromSeconds  10 L, clock)\n   let  randomWalk = Sample.randomWalk  \" randomWalk \" \n   let  walkPipe =  Events.events | >  Pipe.tickTimer randomWalk (TimeSpan.FromMilliseconds  500. )\n   let  systemMetrics = Events.events | >  Pipe.tickTimer (systemMetrics (PointName.parse  \" sys \" )) (TimeSpan.FromSeconds  10. )\n   let  processing =\n    Events.compose [\n       walkPipe\n       | >  Events.sink [ \" WalkFile \" ;]\n\n       walkPipe\n       | >  Pipe.choose (Message.tryGetGauge  \" randomWalk \" )\n       | >  Pipe.counter ( fun  _ - >   1 L) (TimeSpan.FromSeconds  2. )\n       | >  Pipe.map ( fun  counted - >  Message.eventFormat (Info,  \" There are {totalNumbers} randomWalk within 2s \" , [|counted|]))\n       | >  Events.sink [ \" Console \" ;]\n\n       walkPipe\n       | >  Pipe.choose (Message.tryGetGauge  \" randomWalk \" )\n       | >  Pipe.map ( fun  _ - >   1 L)  // think of randomWalk as an event, mapping to 1 \n       | >  Pipe.tickTimer tenSecondsEWMATicker (TimeSpan.FromSeconds  5. )\n       | >  Pipe.map ( fun  rate - >  Message.eventFormat (Info,  \" tenSecondsEWMA of randomWalk ' s rate is {rateInSec} \" , [|rate|]))\n       | >  Events.sink [ \" Console \" ;]\n\n       systemMetrics\n       | >  Pipe.map Array.toSeq\n       | >  Events.flattenToProcessing\n       | >  Events.sink [ \" LiterateConsole \" ;  \" WPCMetricFile \" ;]\n    ]\n\n   let  console = Console.create Console.empty  \" Console \" \n   let  literalConsole = LiterateConsole.create LiterateConsole.empty  \" LiterateConsole \" \n   let  randomWalkFileName = File.Naming ( \" {service}-RandomWalk-{date} \" ,  \" log \" )\n   let  wpcFileName = File.Naming ( \" {service}-wpc-{date} \" ,  \" log \" )\n   let  randomWalkTarget = File.create (File.FileConf.create Environment.CurrentDirectory randomWalkFileName)  \" WalkFile \" \n   let  wpcFileTarget = File.create (File.FileConf.create Environment.CurrentDirectory wpcFileName)  \" WPCMetricFile \" \n   let  logary =\n    Config.create  \" Logary.Examples.MetricsWriter \"   \" localhost \" \n    | >  Config.targets [console; literalConsole; randomWalkTarget; wpcFileTarget;]\n    | >  Config.ilogger (ILogger.Console Verbose)\n    | >  Config.processing processing\n    | >  Config.build\n    | >  run\n\n  mre.Wait()\n   0 By wrapping it up like this, you can drastically reduce the amount of code a given service sends by pre-computing much of it. It ' s also a good sample of reservoir usage; a fancy name of saying that it ' s an algorithm that works on more than one gauge at a time, to produce a derived metric.   git clone git@github.com:logary/logary.git   cd logary   ./fake.sh build If you have to install .Net Core first:   brew cask install dotnet-sdk Now ensure your shell has something like this as initialisation logic:   export PATH= \" /usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin \"   eval `/usr/libexec/path_helper -s`   export DOTNET_CLI_TELEMETRY_OPTOUT=1 Or otherwise, you ' ll have a hard time building. We recommend using Rider, rather than anything else to write F#, since this is a rather large project:   export DOTNET_CLI_TELEMETRY_OPTOUT=1 You ' ll find Rider in your Applications folder. PointName Context Rule  &  Hierarchical logging  &  Filter  &  Minimum level Log Level Logging from modules Logging from a class Logging fields  &  templating Metrics  &  EventProcessing pipeline Building Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/docs\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-dotnet-documentation"},"8":{"id":"8","title":"FAQs","subtitle":["FAQ","Getting MissingMethodException from FSharp.Core","Getting MissingMethodException from Hopac.Core","Is v5.0.x a stable version?","Isn","'","t v4.0.x supposed to be API-stable?","Why does Logary depend on FParsec?","Why do you depend on Hopac?","How do I use Hopac from C#?","What","'","s logVerboseWithAck, logWithAck and how does it differ from logSimple?","Comparison to NLog and log4net","Comparison to Codahale metrics ","&"," Metrics.NET","Comparison with Serilog"],"description":"","body":"FAQs Logary Analytics Start FAQs   Expected reading time:  2  minutes You need to add a rebind to the latest F# version in your executable: < ?xml version= \" 1.0 \"  encoding= \" utf-8 \" ? > \n < configuration > \n   < runtime > \n     < assemblyBinding   xmlns = \" urn:schemas-microsoft-com:asm.v1 \" > \n       < dependentAssembly > \n         < Paket > True < / Paket > \n         < assemblyIdentity   name = \" FSharp.Core \"   publicKeyToken = \" b03f5f7f11d50a3a \"   culture = \" neutral \"  / > \n         < bindingRedirect   oldVersion = \" 0.0.0.0-999.999.999.999 \"   newVersion = \" 4.4.0.0 \"  / > \n       < / dependentAssembly > \n     < / assemblyBinding > \n   < / runtime > \n < / configuration > Inspect the version specified in the   Logary package   and ensure that you have that exact version installed. Hopac is currently pre-v1 so it is often doing breaking changes between versions. It ' s stable to run. The API is alpha. We ' re not doing pre-release versions because they make it impossible for other packages to be released as stable versions. But we need to work through Logary in production; as such you can imagine that qvitoo is taking the risk and cost of making v4.0 RTM as stable and reliable as can be. For tow reasons; we use Chiron for json formatting which depend on FParsec Aether is vendored in Logary.Utils.Aether and depend on it. We previously depended on Newtonsoft.Json, but that library is often depended on from other packages and we want Logary to be as free of dependencies as possible, in order to make it as stable as possible. Hopac supports a few things that async doesn ' t: Rendezvous and selective concurrency primitives (select A or B) Negative ACKs instead of CancellationToken-s We also wanted support for synchronous rendezvous between channels/job/alts/promises/etc. This still supports asynchronous operations towards the outside. Together it makes for an excellent choice for cooperating  ' agents ' , like the Registry and Supervisor and Target Instance that we have in the library. Besides the technical upsides, it ' s a good thing there ' s a book written about the concurrency model that Hopac implements â€“   Concurrent Programming in ML   which lets us get developers up to speed quickly. Finally, our unit tests sped up 30x when porting from Async. The performance boost is a nice feature of a logging framework and comes primarily from less GC collection and the  ' hand off '  between synchronising concurrency primitives being synchronously scheduled inside Hopac rather than implemented using Thread/Semaphore/Monitor primitives on top of the ThreadPool. You ' re better off following the examples in C# and using the Task-wrapped public APIs than going spelunking into the dire straits of Hopac and F#. Just pull in Logary.CSharp to make this happen. You ' ll also have to open the Logary namespace. To start with, if you ' re new to Logary, you can use logSimple and it will work like most other logging frameworks. So what are those semantics exactly? Logary runs its targets concurrently. When you log a Message, all targets whose Rules make it relevant for your Message, receives the Message, each target tries to send that Message to its, well, target. Because running out of memory generally is unwanted, each target has a   RingBuffer   that   the messages are put into   when you use the Logger. Unless all targets '  RingBuffer accept the Message, the call to log doesn ' t complete. This is similar to how other logging frameworks work. But then, what about the call to log? Behind the scenes it calls lockWithAck and tries to commit to the returned Alt [Promise [unit]] (the outer Alt, that is). If the RingBuffer is full then this Alt cannot be committed to, so there ' s code that drops the log message after 5000 ms. Hence; logSimple tries its best to log your message but if you app crashes directly after calling logSimple or your Logstash or other target infrastructure is down, you cannot be sure everything is logged. The decision was made that it ' s more important that your app keeps running than that all targets you have configured successfully log your Messages. The outer Alt ensures that the Message has been placed in all configured targets '  RingBuffers. The inner Promise that the Message has successfully been written from all Targets that received it. It ensures that your logging infrastructure has received the message. It ' s up to each target to deal with Acks in its own way, but a  ' best-practices '  Ack implementation can be seen in the RabbitMQ target. It ' s a best-practices Ack implementation because RabbitMQ supports publisher confirms (that serve as Acks), asynchronous publish and also durable messaging. The C# signature of the above functions is as follows: type Message =\n  [ < Extension > ]\n   static  member  LogWithAck  ( logger, message, bufferCt, promiseCt ) : Task < Task >  =\n    Alt. toTasks bufferCt  promiseCt  ( Logger.logWithAck logger message ) and can be used like so: var  message = MessageModule.Event(LogLevel.Warn,  \" Here be dragons! \" );\n // force the buffers of all configured targets to be flushed \n await  logger.LogWithAck(message); Why Logary instead of one of the classic logging frameworks? You get semantic logging with Logary More targets to choose from Larger community of target writers Easier to write targets; they can crash and that ' s handled by Logary internally Support for zero-dependency usage through Logary.Facade Better/more extensive Rule-based hierarchies Targets can be decoupled from the network and Ack is a first-level primitive You get back an   Alt (Promise (unit) )  that you can use to synchronise your calling code for when the log message is required to be durable; you can ' t do this with NLog or log4net There ' s an object model you can use from the calling code Logary is F#, so it ' s easier to keep bug-free relative to many other languages Logary doesn ' t keep static state around; easy to refactor, easy to extend Why Logary rather than Metrics.NET, the primary alternative? In order to understand the differences, you first need to understand the vocabulary. Logary uses the name   Message   to mean either an  Event   , a   Gauge   or a   Derived  . This comes from analysing the different sorts of things one would like to ship from an app. Starting with an   Event  ; this is the main value when you ' re logging (in fact, it ' s Logary.PointValue.Event(template:string) that you ' re using.) An event is like a Gauge at a particular instant on the global timeline with a value of 1 (one). Which brings us to what a   Gauge   is. It ' s a specific value at an instant. It ' s what you see as a temporature on a thermometer in your apartment, e.g.   10.2 degrees celcius  . In the International System of Units (SI-Units), you could say it ' s the same as 283.2 K. Logary aims to be the foundational layer for all your metrics, so it uses these units. A   Gauge   value of your temperature could be created like so   Message.gaugeWithUnit Kelvin (Float 283.2)   or   Gauge (Float 283.2, Kelvin)  . A   Derived metric  , like   Kelvin/s   is useful if you ' re planning on writing a thermostat to control the temperature. A change in target temperature causes a rate of change. Another sample metric could be represented by the name   [|  \" MyApp \" ;  \" API \"   \" requests \"  |]   and   PointValue   of   Derived (Float 144.2, Div (Scalar, Seconds))  , if the API is experiencing a request rate of 144.2 requests per second. Armed with this knowledge, we can now do a mapping between Codahale ' s metrics and those of Logary:  Gauges   (measuring instantaneous values) - >    PointValue.Gauge(.., ..)  .  Timers   (measuring durations) - >    PointValue.Gauge(.., Scaled(Seconds, 10e9)   (in nanoseconds)  Meter   (measuring rates) - >    PointValue.Derived(.., Div(Scalar, Seconds))   or   PointValue.Derived(.., Div(Other  \" requests \" , Seconds))    Counters   (counting events) - >    PointValue.Event( \" User logged in \" )  Histograms   (tracking value distributions) - >    PointValue.Derived   (with suffixes) and   Reservoirs.  Metrics like the above are taken from different sources: At call site (e.g.  \"  Event   happened \" , or  \" it took   50 ns to connect  \" ) At a process level, derived from  Gauge   and   Event   from different call-sites in your app (e.g.  \" The 99.9th percentile of  ' [time] ns to connect '  is 145 ns \" ). At process level, taken from the operating system (Process is using 36.3% of CPU) At a system level (e.g. the CPU utilisation is 0.352% â€“ which can be represented as let  mhz = Div(Scaled(Hz,  1e-6 ))  in  Gauge(Fraction ( 1300 ,  36800 ), Div(mhz, mhz)) as collected by Rutta ' s Shipper from a compute node. The aim of Logary is to connect values from call-sites, to configurable derivations, such as percentiles(, potentially again to derivations), and finally to targets which can then store them. Both support structured logging Both run on .Net Logary is based on cooperative multithreading whilst Serilog is mostly lock-free concurrent Logary was built from running high-throughput distributed systems 24/7 in production and has learnt its lessons similar to Serilog. Logary can be run in multi-instance mode without using any global shared state (aka. statics), which is similar to Serilog Serilog ' s Enrichers = Logary ' s middleware Serilog ' s Sink = Logary ' s Target Targets in Logary tend to use IO completion ports/async-as- \" green threads \" , AFAIK Sinks are running and calling out using synchronous/blocking APIs to a larger extent Logary supports flushing all targets ( LogManager.Flush ) Logary supports flushing a single target ( Target.flush ) Logary supports backpressure (F#:  Alt < _ >  , C#:  Task ) returned from logWithAck . Logary further supports backpressure by waiting for all targets to flush a particular message (e.g. you should always block on Fatal messages to finish logging) through  Alt < Promise < unit > > / Task < Task >  in C# (same method as above). Logary ' s C# API doesn ' t support misconfiguring Logary, because it ' s been built with chaining types together (going beyond the  return this  pattern) â€“ similar to Serilog but with a more callback-oriented API. Logary supports Metrics â€“ Gauges, Derived values, Histograms, Reservoirs Logary supports Health checks out of the box Logary has built-in support for Windows Performance Counters metrics shipping through  Logary.Metrics.WinPerfCounters . Logary provides a Facade for your libraries to depend on, to avoid dependency hell forcing you to upgrade all your libraries whenever Logary changes (which it does often, in order to improve!) â€“ a single  Facade.[fs,cs] -file that you version control yourself. Logary supports Targets that batch, out of the box, similar to Serilog. The Target is responsible for choosing how many  Messages  it can send at once. Logary supports Targets that fail by restarting them Logary supports Targets '  last will â€“ use to handle poison Messages Logary is written in F#, Serilog in C# Logary has a C# API  Logary.CSharp . Serilog doesn ' t have a F# API Logary supports adding structured data to metrics Logary ' s InfluxDb target supports fields and can batch multiple Windows Performance Counters or metrics into a single Measurement Logary has a JS-counterpart,  logary-js  which lets you log into Logary.Services.Rutta  on the server; events and metrics. Logary has paid support available if you need it. Logary supports the side-kick pattern, where you outsource your shipping of logs from your main process to a co-process through Rutta ' s Shipper and Router. Logary has  TimeScope  and the ability to instrument your code for sending timing information. Logary has preliminary support for Zipkin. Both are awesome and @nblumhardt is an awesome dude. Use whichever you feel most comfortable with! FAQ Comparison to NLog and log4net Comparison to Codahale metrics  &  Metrics.NET Comparison with Serilog Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/faqs\",\"query\":{},\"buildId\":\"development\"}","href":"/faqs"},"9":{"id":"9","title":"Tutorials","subtitle":["File guidelines â€“ module vs static method","File guidelines â€“ plural vs singular","Namespace guidelines â€“ ","or not","RuntimeInfo and internal logging","When to write a new function?","How to open namespaces?","To start the job or not?","Writing a new target"],"description":"","body":"Tutorials Logary Analytics Start Tutorials   Expected reading time:  3  minutes Clone it like above. Ensure you can build it. Open   Logary.sln  . Make a change, send a PR towards master. To balance the app.config files, try   mono tools/paket.exe install --redirects --clean-redirects --createnewbindingfiles Declare your interfaces in a   MyIf.fs   and its module in   MyIfModule.fs   with a ([CompilationRepresentation(CompilationRepresentationFlags.ModuleSuffix)])). Place these files as high as possible. Place the module as close to and below the non-module file as possible. If it ' s plausible that one would like to use point-free programming with your functions, place them in a module. (E.g. Message versus MessageModule) Factory methods go on the types for value types. For stateful objects they go on the module, named   create   which may or may not return a   Job[]   of some public state type with a private/internal constructor. (E.g. PointName versus Engine) All implementations go in a plural namespace. E.g.   Logary.Metrics.Ticked   has: Logary  â€“ core namespace Metrics  â€“ namespace for all metrics implementations Ticked  â€“ a module and/or type that implements Logary-based ticking/ scheduling. Another example:   Logary.Target  , which is a module that implements logic about the life-cycle of target instances. It ' s used to start/stop/pause and shutdown targets. It ' s singular.  Logary.Internals  Things that end-users of the library are not likely to configure should go in  Logary.Internals  . Examples include   Logary.Internals.Globals   and   Logary.Internals.RuntimeInfo   (which is configured with the config API instead). The   RuntimeInfo   and internal   Logger   should be propagated to the modules and objects that you build your solution out of. This guideline is mostly about the registry ' s implementation and its interaction with config and services. Generally, keep your functions to a single responsibility and compose functions instead of extending existing functions. Composition happens through currying and partial application of  ' state '  or  ' always-this-value '  values. For state it can both go through the Services abstraction (start/pause/stop/etc) or by closing over the state with a function. If you find that your functions are getting larger than 3 lines of code, you should probably extract part of the function. By  ' default '  it ' s better to be 1% less performant but 5% more readable, after this list of priorities: Correct CReadable/SRPorrect Fast/efficient/performant Prefer to open a namespace over fully qualifying a type. Prefer to open fully qualified over partial. open  Logary.Internals  open  Logary.Internals.Supervisor Instead of open  Logary.Internals  open  Supervisor A module function like   MyModule.create : Conf - >  Job[T]   should not start the server loop. Instead, just return a cold job (that can be started multiple time) and let the composition  \" root \" , such as the   Registry  , perform the composition and lifetime handling. Are you thinking of creating a new Target for Logary? It ' s a good idea if you can ' t find the right Target for your use case. It can also be useful if you have an internal metrics or log message engine in your company you wish to ship to. Create a new .net 4.5.1 class library in F#, under target and add that to Logary.sln. Copy the code from Logary ' s Targets/Noop.fs, which contains the basic structure. There are more docs in this file, to a file named MyTarget.fs in your new project. Add a nuget reference (or project reference if you ' re intending to send a PR) to Logary Write your Target and your Target ' s tests to ensure that it works Remember to test when the call to your server throws exceptions or fails You should use   Http.fs   as the HTTP client if it ' s a HTTP target When writing the Target, it ' s useful to keep these guidelines in mind. It should be able to handle shutdown messages from the shutdown channel It should not handle  ' unexpected '  exceptions, like network loss or a full disk by itself, but instead crash with an exception â€“ the Logary supervisor will restart it after a short duration. Things that are part of the target API, like different response status codes of a REST API should be handled inside the Target. Don ' t do blocking calls; Convert  Task < _ >  and  Async < _ >  to  Job < _ >  by using the Hopac conversion methods If you need to block, use  Scheduler.isolate  so that your blocking call doesn ' t stop all Targets. Choose whether to create a target that can re-send crashing messages by choosing between  TargetUtils.[willAwareNamedTarget, stdNamedTarget] You can choose between consuming Messages one-by-one through RingBuffer.take  or in batches with  RingBuffer.takeBatch If you take a batch and the network call to send it off fails, consider sending the batch to the  willChannel  and throw an exception. Your target will be re-instantiated with the batch and you can now send the messages one-by-one to your target, throwing away poison messages (things that always crash). If your target throws an exception, the batch of Messages or the Message you ' ve taken from the  RingBuffer  will be gone, unless you send it to the will  channel. Exiting the loop will cause your Target to shut down. So don ' t catch all  exceptions without recursing afterwards. The supervisor does  not restart targets that exit on their own. If your target can understand a service name, then you should always add the service name from  RuntimeInfo.serviceName  as passed to your loop function. The  RuntimeInfo  contains a simple internal logger that you can assume always will accept your Messages. It allows you to debug and log exceptions from your target. By default it will write output to the STDOUT stream. If you don ' t implement the last-will functionality, a caller that awaits the Promise in  Alt < Promise < unit > >  as returned from  logWithAck , will block forever if your target ever crashes. If you need to do JSON serialisation, consider using  Logary.Utils.Chiron and  Logary.Utils.Aether , which are vendored copies of Chiron  and  Aether . Have a look at the Logstash Target  for an example. When your Target is finished, either ping  @haf  on github,  @henrikfeldt  on twitter, or send a PR to this README with your implementation documented. I can assist in proof-reading your code, to ensure that it follows the empirical lessons learnt operating huge systems with Logary. File guidelines â€“ module vs static method File guidelines â€“ plural vs singular Namespace guidelines â€“ Logary.Internals or not RuntimeInfo and internal logging When to write a new function? How to open namespaces? To start the job or not? Writing a new target Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/tutorial\",\"query\":{},\"buildId\":\"development\"}","href":"/tutorials"},"10":{"id":"10","title":"License","subtitle":[],"description":"","body":"License Logary Analytics Start License   Expected reading time:  1  minutes GPL v3, Apache 2.0 and MIT depending on library License Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/license\",\"query\":{},\"buildId\":\"development\"}","href":"/license"},"11":{"id":"11","title":"Prometheus","subtitle":["Prometheus"],"description":"","body":"Prometheus Logary Analytics Start Prometheus xmlSpace= \" preserve \" >   Expected reading time:  2  minutes Logary supports Prometheus. Reference   Logary.Prometheus   and create metrics: TBD module  A =\n   open  Logary.Metric\n\n   let  logger = Log.create  \" xxx.yyy \" \n\n   let  parseConfigFailedCounter =\n    GaugeConf.create {name= \" xxx_yyy_parse_config_faild_total \" ; description=  \" the total number for xxx.yyy.parseConfig faild \" ; labelNames = [|  \" path \"  |]}\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n\n   // add gauge metric and histogram with buckets [| 0.001; 0.005; 0.01; 0.025; 0.05; 0.1; 1.0|] in the same time \n   let  parseConfigGaugeWithHistogram =\n    GaugeConf.create {name= \" xxx_yyy_parse_config_latency_seconds \" ; description=  \" xxx.yyy.parseConfig latency in seconds \" ; labelNames = [||]}\n    | >  GaugeConf.withHistogram [|  0.001 ;  0.005 ;  0.01 ;  0.025 ;  0.05 ;  0.1 ;  1.0 |]\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n    | >  Metric.noLabels\n\n\n   // using default buckets:  [| 0.005; 0.01; 0.025; 0.05; 0.075; 0.1; 0.25; 0.5; 0.75; 1.; 2.5; 5.0; 7.5; 10. |] \n   let  parseConfigLatencyHistogram =\n    HistogramConf.create( \" xxx_yyy_parse_config_latency_seconds \" ,  \" xxx.yyy.parseConfig latency in seconds \" )\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n    | >  Metric.noLabels\n\n   // using hookup and shortcut style \n   let  parseConfigWithShortcut path =\n     try \n       // if we hook up metric at logary ' s conf, then there is no need to do other things here. \n       // span will be treated as gauges when span has been finished. \n       use  traceSpan =\n        logger.buildSpan()\n        | >  Span.setMessage (eventX  \" time usage about parse config with {path} \"   > >  setField  \" path \"  path)\n        | >  Span.start\n\n       // do some work here \n      failwith  \" not implement \" \n      \n     with  ex - > \n      eventX  \" parse config from {path} failed \" \n       > >  setField  \" path \"  path\n       > >  enableCounterMetric {name= \" xxx_yyy_parse_config_faild_total \" ; description=  \" the total number for xxx.yyy.parseConfig faild \" ; labelNames = [|  \" path \"  |]}\n      | >  logger.error\n\n   // using metric as a separate instance style \n   let  parseConfig path =\n     try \n       let  traceSpan =\n        logger.buildSpan()\n        | >  Span.setMessage (eventX  \" time usage about parse config with {path} \"   > >  setField  \" path \"  path)\n        | >  Span.start\n\n       // do some work here \n      failwith  \" not implement \" \n\n\n       let  spanLog = traceSpan.finish id\n       // gauge with histogram like below \n      parseConfigGaugeWithHistogram.set (Duration.FromTicks(spanLog.duration).TotalSeconds)\n       // or metric only histogram like below \n      parseConfigLatencyHistogram.observe (Duration.FromTicks(spanLog.duration).TotalSeconds)\n\n     with  ex - > \n      eventX  \" parse config from {path} failed \" \n       > >  setField  \" path \"  path\n      | >  logger.error\n\n      (parseConfigFailedCounter.labels [| path |]).inc  1. Prometheus Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/prometheus\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-prometheus-dotnet"},"12":{"id":"12","title":"Logary Rutta","subtitle":["Install the Helm chart","Install the Helm chart","Rutta Router mode","Usage1","Usage2","In depth","The Shipper â€“ from environment to Proxy or Router","The Proxy â€“ from Shipper to Router","The Router â€“ from Shipper or Proxy to Target"],"description":"","body":"Logary â€” Rutta â€“ cloud native log router and event/log ingress Logary Analytics Start Logary Rutta   Expected reading time:  2  minutes The first step is to install the Rutta Helm chart into your Kubernetes cluster. Rutta is a high-performance log router/shipper written in F# but configured from the command line. It ' s  \" cloud native \"  in that it runs as a docker container on top of .Net Core Rutta is GPLv3 licensed (or alternatively commercially licensed). It ' s a packaging of Logary as a service, that you can run, either as a sidecar container or as a log router deployment. Rutta is completely stateless, so you can run any number of replicas. It runs as a Kubernetes deployment with three replicas by default. A common configuration for Rutta is to configure a Stackdriver target, a HTTP ingestion listener as well as a UDP ingestion listener. Your apps send UDP log messages to the UDP endpoint and your frontends (native apps and web sites) send HTTP messages to the HTTP endpoint. Rutta when batch-ships these log messages into Stackdriver. By default this chart exposes a HTTP listener/endpoint and prints to console; in order for it to log to Stackdriver, AliYun or AppInsights, you have to configure those explicitly in the values file. Have a look at the values.yaml file in order to get an idea of what you can configure. The first step is to install the Rutta Helm chart into your Kubernetes cluster. helm install https://github.com/logary/logary/tree/master/src/services/rutta-helm-chart  & &  \\\n    --name rutta  & &  \\\n    --namespace monitoring Or if you ' ve downloaded the chart; helm install ./rutta-helm-chart  & &  \\\n    --name rutta  & &  \\\n    --namespace monitoring If you use a local values file, you can upgrade the chart. helm upgrade --debug --install rutta  & &  \\\n    ./rutta-helm-chart  & &  \\\n    --namespace monitoring  & &  \\\n    --values values/rutta.yaml The router mode lets you take inputs from a `listener` (tcp, udp, ...), interpret it with a `codec` and then send it to a `target`. Route, forward and print logs anywhere to anything. docker run -p 10001:10001 --rm -it haaf/rutta router --listener tcp 0.0.0.0:10001 json --target console://./ Rutta is software for shipping Messages between computers. Either from your own services or from Windows Performance Counters. This is useful if you want your services to ship all logs to a central point, before batching it and sending it off to InfluxDb. It ' s also useful if you want to firewall off a single subnet for certain processing and only have a single point ship logs and metrics. v1: Hard-coded supported target types. Initially we ' ll just support InfluxDB. v2: More configurable target configuration that supports any target. This service can run in three modes; Shipper, Router and Proxy. Servers can be implemented using Hopac ' s lightweight servers. Communication is implemented using ZMQ and a binary serialisation format. Bindings look may look like this: Shipper - >  Router Shipper - >  Proxy Proxy - >  Proxy Proxy - >  Router   ZMQ socket reference On Windows you do   ./rutta.exe -- --pub-to ...   - note the two extra dashes before the parameter list. This is to avoid Topshelf munching the arguments away. Enables log shipping from hosts that are not directly connected to the router nor to InfluxDB.  Shippers CONNECT PUSH sockets to the Router ' s PULL socket. See   http://lists.zeromq.org/pipermail/zeromq-dev/2012-February/015917.html During network splits, the sending  PUSH socket blocks . During network splits, the sending XPUSH socket drops messages. Proxies take inputs from Shippers or other Proxies that publish Messages using XPUB sockets: The Proxy is run this way, by providing a XSUB socket binding and a XPUB socket binding: During network splits, the receiving   XSUB socket drops messages. You can then connect to the Proxy with a Router that routes it to the final Target (like InfluxDB in this example): During network splits, the sending   XPUB socket drops messages. Implements Fan-In using PULL or SUB of Messages from ZMQ. Forwards internally to a Target. V1 only implements the InfluxDB target. BINDs a PULL socket on a specified NIC/IP and PORT. Configures a single internal Target that pushes the received data. During network splits, the listening   PULL socket blocks.  BINDs a SUB socket on a specified NIC/IP and POST. Configures a single internal Target that pushes the received data.  Serialisation  for Rutta is done using   FsPickler. Since FsPickler uses a binary format, it should be assumed to break for any given minor upgrade of FsPickler. Each ZMQ message contains a Message (see DataModel.fs) in the binary form given by the serialiser chosen. Introduction Install the Helm chart Rutta architecture Usage1 Usage2 In depth The Shipper â€“ from environment to Proxy or Router The Proxy â€“ from Shipper to Router The Router â€“ from Shipper or Proxy to Target Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/rutta\",\"query\":{},\"buildId\":\"development\"}","href":"/logary-rutta"},"13":{"id":"13","title":"Pricing","subtitle":["Calculator","Purchase license"],"description":"","body":"Logary â€” Pricing Logary Analytics Start Pricing Logary ' s pricing is transparent. You don ' t have to sign up to a newsletter to know what it would cost you to run it for your for-profit service. Licenses are yearly and subscription based. You can load- and stress-test in a test-/staging-environment, for free, as long as that environment never serves production traffic. Number of cores in total production deployment 1 core 8 cores 30 cores Number of developers owning/working on the software (seats) 1 developer 3 developers 15 developers Number of years to buy a license for 1 year 2 years 15 years Total (excl VAT):  2220  EUR Subsequent years:  444  EUR Your license will be delivered by e-mail upon purchase. Card details Pay  2220  EUR Calculator Purchase license Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/pricing\",\"query\":{},\"buildId\":\"development\"}","href":"/pricing"}}